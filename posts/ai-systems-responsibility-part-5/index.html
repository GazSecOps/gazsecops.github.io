<!doctype html><html lang=en><head><title>AI Systems Responsibility: Part 5 - When to Say No (And How to Make It Stick) :: Gareth's Engineering Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=" Management: We need to deploy the customer sentiment analysis model by end of week.
Sysadmin: It&rsquo;s not ready.
Management: The client&rsquo;s expecting it.
Sysadmin: It fails on 30% of non-English inputs. Your client has international customers.
Management: We&rsquo;ll fix that in the next release.
Sysadmin: No.
Management: What do you mean, no?
Sysadmin: I mean no. We&rsquo;re not deploying broken software because someone made a promise we can&rsquo;t keep.
This conversation never goes well. Have it anyway.
&#34;The person saying 'we can't ship this' is always the bad guy. Right up until production breaks and suddenly everyone's asking why we didn't catch this in testing.&#34; Part 5 of the series. This one&rsquo;s about saying no. When to do it, how to do it, and how to not get fired for it.
"><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://gazsecops.github.io/posts/ai-systems-responsibility-part-5/><link rel=stylesheet href=https://gazsecops.github.io/css/extended.min.c658c723e006469d82f697e19c5338967fad12c57650bdd915bacf9cfbe2cc38.css><link rel=stylesheet href=https://gazsecops.github.io/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css><link rel=stylesheet href=https://gazsecops.github.io/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css><link rel=stylesheet href=https://gazsecops.github.io/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css><link rel=stylesheet href=https://gazsecops.github.io/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css><link rel=stylesheet href=https://gazsecops.github.io/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css><link rel=stylesheet href=https://gazsecops.github.io/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css><link rel=stylesheet href=https://gazsecops.github.io/css/main.min.36833afd348409fc6c3d09d0897c5833d9d5bf1ff31f5e60ea3ee42ce2b1268c.css><link rel=stylesheet href=https://gazsecops.github.io/css/menu.min.3c17467ebeb3d38663dce68f71f519901124fa5cbb4519b2fb0667a21e9aca39.css><link rel=stylesheet href=https://gazsecops.github.io/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css><link rel=stylesheet href=https://gazsecops.github.io/css/post.min.e6dddd258e64c83e05cec0cd49c05216742d42fc8ecbfbe6b67083412b609bd3.css><link rel=stylesheet href=https://gazsecops.github.io/css/syntax.min.a0773cce9310cb6d8ed23e50f005448facf29a53001b57e038828daa466b25c0.css><link rel=stylesheet href=https://gazsecops.github.io/css/terminal.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css><link rel=stylesheet href=https://gazsecops.github.io/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css><link rel="shortcut icon" href=https://gazsecops.github.io/favicon.png><link rel=apple-touch-icon href=https://gazsecops.github.io/apple-touch-icon.png><meta name=twitter:card content="summary"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="AI Systems Responsibility: Part 5 - When to Say No (And How to Make It Stick)"><meta property="og:description" content=" Management: We need to deploy the customer sentiment analysis model by end of week.
Sysadmin: It&rsquo;s not ready.
Management: The client&rsquo;s expecting it.
Sysadmin: It fails on 30% of non-English inputs. Your client has international customers.
Management: We&rsquo;ll fix that in the next release.
Sysadmin: No.
Management: What do you mean, no?
Sysadmin: I mean no. We&rsquo;re not deploying broken software because someone made a promise we can&rsquo;t keep.
This conversation never goes well. Have it anyway.
&#34;The person saying 'we can't ship this' is always the bad guy. Right up until production breaks and suddenly everyone's asking why we didn't catch this in testing.&#34; Part 5 of the series. This one&rsquo;s about saying no. When to do it, how to do it, and how to not get fired for it.
"><meta property="og:url" content="https://gazsecops.github.io/posts/ai-systems-responsibility-part-5/"><meta property="og:site_name" content="Gareth's Engineering Blog"><meta property="og:image" content="https://gazsecops.github.io/og-image.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="627"><meta property="article:published_time" content="2026-01-09 10:00:00 +0000 UTC"></head><body><div class="container center"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>gareth@blog:~$</div></a></div><div class=header__search><input type=text id=header-search placeholder="Quick search..." style="padding:5px 10px;background:#222;color:#eee;border:1px solid #444;border-radius:3px;font-size:14px;width:200px"></div><ul class="menu menu--mobile"><li class=menu__trigger>Menu&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=/topics/>Topics</a></li><li><a href=/posts/>All</a></li><li><a href=/series/>Series</a></li><li><a href=/tags/>Tags</a></li><li><a href=/archive/>Archive</a></li><li><a href=/search/>Search</a></li><li><a href=/about/>About</a></li></ul></li></ul></div><nav class=navigation-menu><ul class="navigation-menu__inner menu--desktop"><li><a href=/topics/>Topics</a></li><li><a href=/posts/>All</a></li><li><a href=/series/>Series</a></li><li><a href=/tags/>Tags</a></li><li><a href=/archive/>Archive</a></li><li><a href=/search/>Search</a></li><li><a href=/about/>About</a></li></ul></nav></header><script>(function(){const e=document.getElementById("header-search");if(!e)return;e.addEventListener("keydown",function(e){if(e.key==="Enter"){const e=this.value.trim();e&&(window.location.href="/search?q="+encodeURIComponent(e))}}),document.addEventListener("keydown",function(t){t.key==="/"&&!["INPUT","TEXTAREA"].includes(t.target.tagName)&&(t.preventDefault(),e.focus()),t.key==="Escape"&&t.target===e&&e.blur()})})()</script><style>.header__inner{display:flex;align-items:center;gap:20px}.header__search{flex:none}#header-search::placeholder{color:#666;font-style:italic}#header-search:focus{outline:none;border-color:#888}@media(max-width:684px){.header__search{display:none}}</style><div class=content><article class=post><h1 class=post-title><a href=https://gazsecops.github.io/posts/ai-systems-responsibility-part-5/>AI Systems Responsibility: Part 5 - When to Say No (And How to Make It Stick)</a></h1><div class=post-meta><time class=post-date>2026-01-09</time><span class=post-author>Gareth</span><span class=post-reading-time>9 min read (1715 words)</span></div><span class=post-tags>#<a href=https://gazsecops.github.io/tags/ai/>ai</a>&nbsp;
#<a href=https://gazsecops.github.io/tags/management/>management</a>&nbsp;
#<a href=https://gazsecops.github.io/tags/operations/>operations</a>&nbsp;
#<a href=https://gazsecops.github.io/tags/series/>series</a>&nbsp;</span><div class=table-of-contents><h2>Table of Contents</h2><nav id=TableOfContents><ul><li><a href=#when-to-say-no>When to Say No</a></li><li><a href=#pre-deployment-checklist-the-minimum-bar>Pre-Deployment Checklist (The Minimum Bar)</a></li><li><a href=#how-to-say-no-the-first-time>How to Say No (The First Time)</a></li><li><a href=#how-to-say-no-when-they-push-back>How to Say No (When They Push Back)</a></li><li><a href=#when-youll-lose>When You&rsquo;ll Lose</a></li><li><a href=#when-youll-win>When You&rsquo;ll Win</a></li><li><a href=#building-political-capital>Building Political Capital</a></li><li><a href=#what-happens-when-you-dont-say-no>What Happens When You Don&rsquo;t Say No</a></li><li><a href=#the-line-you-cant-cross>The Line You Can&rsquo;t Cross</a></li><li><a href=#part-6-preview>Part 6 Preview</a></li></ul></nav></div><div class=post-content><div><div class=dialogue><p><span class="speaker speaker-management">Management:</span> We need to deploy the customer sentiment analysis model by end of week.</p><p><span class="speaker speaker-sysadmin">Sysadmin:</span> It&rsquo;s not ready.</p><p><span class="speaker speaker-management">Management:</span> The client&rsquo;s expecting it.</p><p><span class="speaker speaker-sysadmin">Sysadmin:</span> It fails on 30% of non-English inputs. Your client has international customers.</p><p><span class="speaker speaker-management">Management:</span> We&rsquo;ll fix that in the next release.</p><p><span class="speaker speaker-sysadmin">Sysadmin:</span> No.</p><p><span class="speaker speaker-management">Management:</span> What do you mean, no?</p><p><span class="speaker speaker-sysadmin">Sysadmin:</span> I mean no. We&rsquo;re not deploying broken software because someone made a promise we can&rsquo;t keep.</p></div><p>This conversation never goes well. Have it anyway.</p><aside class=pullquote>"The person saying 'we can't ship this' is always the bad guy. Right up until production breaks and suddenly everyone's asking why we didn't catch this in testing."</aside><p>Part 5 of the series. This one&rsquo;s about saying no. When to do it, how to do it, and how to not get fired for it.</p><h2 id=when-to-say-no>When to Say No<a href=#when-to-say-no class=hanchor arialabel=Anchor>#</a></h2><p><strong>1. The model hasn&rsquo;t been tested properly</strong></p><p>You ran it on validation data. Got good accuracy. Haven&rsquo;t tested edge cases, haven&rsquo;t tested integration, haven&rsquo;t tested under load.</p><p>This is a no. Doesn&rsquo;t matter how good the accuracy looks. Doesn&rsquo;t matter what management promised.</p><p>Untested models break in production. It&rsquo;s not &ldquo;if.&rdquo; It&rsquo;s &ldquo;when.&rdquo;</p><p><strong>2. The model has known critical failures</strong></p><p>Your fraud detection model works great except it flags all transactions from Alaska as fraudulent. Known issue. Not fixed yet.</p><p>&ldquo;We&rsquo;ll add Alaska to the exception list in production.&rdquo;</p><p>No. Fix it properly or don&rsquo;t ship it.</p><p><strong>3. You can&rsquo;t roll back</strong></p><p>New model ready to deploy. Rollback procedure? &ldquo;We&rsquo;ll figure it out if we need to.&rdquo;</p><p>That&rsquo;s a no. You need a tested rollback procedure before you deploy. Not after things break.</p><p><strong>4. The monitoring doesn&rsquo;t exist</strong></p><p>&ldquo;How will we know if it&rsquo;s working in production?&rdquo;</p><p>&ldquo;We&rsquo;ll watch the logs.&rdquo;</p><p>No. You need proper monitoring. Accuracy tracking, drift detection, latency alerts. Without monitoring, you&rsquo;re flying blind.</p><p><strong>5. Nobody understands how it works</strong></p><p>The data scientist who built it quit. Documentation is sparse. Nobody on the team can explain what it&rsquo;s doing or how to debug it.</p><p>Hard no. You&rsquo;re not deploying a black box that nobody understands.</p><p><strong>6. The model is biased</strong></p><p>Testing shows the model performs significantly worse for certain demographics. Or makes systematically unfair predictions.</p><p>&ldquo;We&rsquo;ll address that in v2.&rdquo;</p><p>No. Fix it now or don&rsquo;t ship it. This isn&rsquo;t just ethics. This is legal liability.</p><p><strong>7. The infrastructure can&rsquo;t handle it</strong></p><p>Model needs 64GB GPU. You have 32GB GPU.</p><p>&ldquo;It&rsquo;ll probably work.&rdquo;</p><p>It won&rsquo;t. Don&rsquo;t ship it.</p><p><strong>8. The risk is disproportionate to the benefit</strong></p><p>Medical diagnosis model that&rsquo;s 70% accurate. &ldquo;It&rsquo;s better than nothing!&rdquo;</p><p>It&rsquo;s not better than nothing. It&rsquo;s dangerous. If you can&rsquo;t get it to acceptable accuracy, don&rsquo;t ship it.</p><h2 id=pre-deployment-checklist-the-minimum-bar>Pre-Deployment Checklist (The Minimum Bar)<a href=#pre-deployment-checklist-the-minimum-bar class=hanchor arialabel=Anchor>#</a></h2><p>Before you say yes to any deployment, verify these:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-markdown data-lang=markdown><span style=display:flex><span>[ ] Model tested on real production-like data (not just validation set)
</span></span><span style=display:flex><span>[ ] Edge cases tested (nulls, unicode, extreme values, adversarial inputs)
</span></span><span style=display:flex><span>[ ] Integration tested with actual upstream/downstream services
</span></span><span style=display:flex><span>[ ] Load tested at 2-3x expected traffic
</span></span><span style=display:flex><span>[ ] Rollback procedure documented and tested (&lt; 5 minutes)
</span></span><span style=display:flex><span>[ ] Monitoring in place (accuracy, latency, error rate, drift detection)
</span></span><span style=display:flex><span>[ ] Alerts configured and tested (someone gets paged when things break)
</span></span><span style=display:flex><span>[ ] Known failure modes documented
</span></span><span style=display:flex><span>[ ] Someone on-call understands how to debug it
</span></span><span style=display:flex><span>[ ] Human fallback available for critical decisions
</span></span></code></pre></div><p>If any box is unchecked, you have grounds to push back. Not &ldquo;I feel uncomfortable&rdquo; - &ldquo;the deployment checklist isn&rsquo;t complete.&rdquo;</p><p>This doesn&rsquo;t guarantee success. It does guarantee you&rsquo;ve done the minimum due diligence.</p><h2 id=how-to-say-no-the-first-time>How to Say No (The First Time)<a href=#how-to-say-no-the-first-time class=hanchor arialabel=Anchor>#</a></h2><p>Start with facts:</p><p>&ldquo;The model fails on edge case X. Here&rsquo;s the test results. Here&rsquo;s the failure rate. We can&rsquo;t ship this.&rdquo;</p><p>Not opinions. Not feelings. Facts. Data. Test results.</p><p>Management response: &ldquo;Can we ship it anyway and fix it later?&rdquo;</p><p>&ldquo;No. Here&rsquo;s why:&rdquo; [Explain the risk. Explain the impact. Explain why fixing it in production is worse than fixing it now.]</p><p>Management response: &ldquo;But we promised the client.&rdquo;</p><p>&ldquo;That&rsquo;s not my problem. My problem is not shipping broken software. Your problem is managing client expectations.&rdquo;</p><p>This will not make you popular. Do it anyway.</p><h2 id=how-to-say-no-when-they-push-back>How to Say No (When They Push Back)<a href=#how-to-say-no-when-they-push-back class=hanchor arialabel=Anchor>#</a></h2><p>They&rsquo;ll push back. They always do. Here&rsquo;s what you&rsquo;ll hear and how to respond:</p><p><strong>&ldquo;We can fix it in production.&rdquo;</strong></p><p>&ldquo;No, we can&rsquo;t. Production issues take longer to fix because we&rsquo;re under pressure, users are affected, and we don&rsquo;t have the same flexibility to test. Fix it now.&rdquo;</p><p><strong>&ldquo;It&rsquo;s good enough for v1.&rdquo;</strong></p><p>&ldquo;Good enough for v1 means it works. This doesn&rsquo;t work. When it breaks, we&rsquo;ll be blamed for shipping something we knew was broken.&rdquo;</p><p><strong>&ldquo;We&rsquo;ll lose the client if we don&rsquo;t ship.&rdquo;</strong></p><p>&ldquo;We&rsquo;ll lose the client faster if we ship broken software. Would you rather delay by two weeks or have the client lose trust completely?&rdquo;</p><p><strong>&ldquo;Can&rsquo;t you just make it work?&rdquo;</strong></p><p>&ldquo;If I could make it work, I would have. It needs proper testing, proper monitoring, and proper infrastructure. That takes time.&rdquo;</p><p><strong>&ldquo;Everyone else is shipping AI. We&rsquo;re falling behind.&rdquo;</strong></p><p>&ldquo;Everyone else is also having 3am incidents because they shipped garbage. We can either ship fast or ship reliable. Pick one.&rdquo;</p><p><strong>&ldquo;Your job is to deploy what we build.&rdquo;</strong></p><p>&ldquo;My job is to keep production running. Deploying broken software makes that impossible.&rdquo;</p><h2 id=when-youll-lose>When You&rsquo;ll Lose<a href=#when-youll-lose class=hanchor arialabel=Anchor>#</a></h2><p>You won&rsquo;t always win. Sometimes management will overrule you. Sometimes they&rsquo;ll deploy it anyway.</p><p>When this happens:</p><p><strong>1. Document everything</strong></p><p>Email confirming your objections. Test results showing the problems. Specific risks identified. Send it to management. CC yourself. Keep a copy.</p><p>Not to cover your arse (though it does that too). To have a record when things break.</p><p><strong>Template for documenting objections:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-fallback data-lang=fallback><span style=display:flex><span>Subject: Deployment Risk Assessment - [Model/System Name]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Summary:
</span></span><span style=display:flex><span>I&#39;m documenting my concerns about deploying [model/system] to production.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Issues Identified:
</span></span><span style=display:flex><span>1. [Specific issue - e.g., &#34;Model fails on non-English inputs (30% failure rate)&#34;]
</span></span><span style=display:flex><span>   - Evidence: [Test results, data, metrics]
</span></span><span style=display:flex><span>   - Impact: [What happens if this breaks in production]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>2. [Next issue]
</span></span><span style=display:flex><span>   - Evidence: [...]
</span></span><span style=display:flex><span>   - Impact: [...]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Recommendation:
</span></span><span style=display:flex><span>[Delay deployment / Fix before shipping / Add compensating controls]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Risk if Deployed Anyway:
</span></span><span style=display:flex><span>- [Specific outcome - e.g., &#34;International customers will receive incorrect predictions&#34;]
</span></span><span style=display:flex><span>- [Business impact - e.g., &#34;Estimated X% of users affected&#34;]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>My Position:
</span></span><span style=display:flex><span>I recommend [not deploying / deploying with conditions] until [specific criteria met].
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>If the decision is to proceed despite these concerns, I request:
</span></span><span style=display:flex><span>1. This email be acknowledged
</span></span><span style=display:flex><span>2. [Specific monitoring/controls] be implemented
</span></span><span style=display:flex><span>3. [Specific rollback criteria] be agreed
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Sent: [Date/Time]
</span></span><span style=display:flex><span>[Your Name]
</span></span></code></pre></div><p>Send this before the deployment. Not after. After is too late.</p><p><strong>2. Demand monitoring</strong></p><p>If they&rsquo;re shipping it anyway, you need monitoring. Not optional. Mandatory. Accuracy tracking, drift detection, error rates, everything.</p><p>When it breaks, you need data to prove what broke and when.</p><p><strong>3. Prepare for the incident</strong></p><p>They&rsquo;re shipping broken software. It will break. Have your incident response ready. Have your rollback tested. Have your escalation path clear.</p><p><strong>4. Don&rsquo;t say &ldquo;I told you so&rdquo;</strong></p><p>When it breaks, resist the urge. Everyone knows you objected. Everyone knows you were right. Saying it out loud just makes you look petty.</p><p>Instead: &ldquo;Here&rsquo;s what broke. Here&rsquo;s how we fix it. Here&rsquo;s how we prevent it next time.&rdquo;</p><p>Be professional even when they weren&rsquo;t.</p><h2 id=when-youll-win>When You&rsquo;ll Win<a href=#when-youll-win class=hanchor arialabel=Anchor>#</a></h2><p>Sometimes they&rsquo;ll listen. Sometimes you&rsquo;ll say no and they&rsquo;ll actually delay the deployment.</p><p>When this happens:</p><p><strong>1. Use the time wisely</strong></p><p>You bought time. Use it to fix the problems properly. Not half-arsed workarounds. Proper fixes.</p><p><strong>2. Communicate progress</strong></p><p>Keep management updated. &ldquo;Here&rsquo;s what we&rsquo;re fixing. Here&rsquo;s the timeline. Here&rsquo;s when we can ship.&rdquo;</p><p>Don&rsquo;t make them regret listening to you.</p><p><strong>3. Ship when it&rsquo;s ready</strong></p><p>Don&rsquo;t rush just because you delayed once. Ship when the tests pass, when the monitoring is in place, when the rollback works.</p><p><strong>4. Make sure it works</strong></p><p>Nothing undermines your credibility faster than saying &ldquo;we need more time&rdquo; and then shipping something that breaks anyway.</p><p>If you demanded time to fix it, fix it properly.</p><h2 id=building-political-capital>Building Political Capital<a href=#building-political-capital class=hanchor arialabel=Anchor>#</a></h2><p>Saying no costs political capital. You need to build it first.</p><p><strong>How to build capital:</strong></p><ul><li>Be right. When you say something will break, it should break. When you say something will work, it should work.</li><li>Fix things quickly. When production breaks, fix it fast. Be reliable.</li><li>Communicate clearly. No jargon. No excuses. Clear explanations of what&rsquo;s happening and why.</li><li>Deliver wins. Ship things that work. Hit deadlines when possible. Be known for getting things done.</li></ul><p><strong>How to spend capital:</strong></p><ul><li>Say no only when it matters. Not every issue is a hill to die on. Pick your battles.</li><li>When you say no, have data. Not opinions, data.</li><li>When you say no, offer alternatives. &ldquo;We can&rsquo;t ship Friday, but we can ship Monday with these fixes.&rdquo;</li></ul><p>You only get to say no if people trust your judgment. Build that trust.</p><h2 id=what-happens-when-you-dont-say-no>What Happens When You Don&rsquo;t Say No<a href=#what-happens-when-you-dont-say-no class=hanchor arialabel=Anchor>#</a></h2><p>You know the model is broken. You know it shouldn&rsquo;t ship. But you don&rsquo;t push back. You deploy it anyway.</p><p>It breaks in production. 3am incident. Rollback. Post-mortem.</p><p>Management: &ldquo;Why didn&rsquo;t we catch this in testing?&rdquo;</p><p>You: &ldquo;We did. I raised concerns.&rdquo;</p><p>Management: &ldquo;Why didn&rsquo;t you push back harder?&rdquo;</p><p>You: &ldquo;I did.&rdquo;</p><p>Management: &ldquo;Not hard enough.&rdquo;</p><p>And suddenly it&rsquo;s your fault for not stopping them from doing the thing they insisted on doing.</p><p>This is unfair. This is also reality.</p><p>When you know something&rsquo;s wrong and you don&rsquo;t say no, you own the consequences.</p><h2 id=the-line-you-cant-cross>The Line You Can&rsquo;t Cross<a href=#the-line-you-cant-cross class=hanchor arialabel=Anchor>#</a></h2><p>There&rsquo;s a line. On one side: push back, document objections, ship when overruled. On the other side: refuse to deploy, escalate over management&rsquo;s head, threaten to quit.</p><p>Where&rsquo;s the line? Depends on the risk.</p><p>Deploying a model with 85% accuracy instead of 90%? Push back, document, ship if overruled.</p><p>Deploying a medical diagnosis model with known critical failures? Escalate. Refuse if necessary.</p><p>You need to know where your line is. Because someday you&rsquo;ll reach it.</p><h2 id=part-6-preview>Part 6 Preview<a href=#part-6-preview class=hanchor arialabel=Anchor>#</a></h2><p>Next time: Case studies. Real examples of AI deployments going wrong. What broke, why it broke, what we can learn.</p><p>Names changed to protect the guilty. Lessons learned the hard way.</p><hr><p><em>Part 5 of N in a series on running AI systems. <a href=/posts/ai-systems-responsibility-part-1/>Part 1: Who Carries the Can?</a> | <a href=/posts/ai-systems-responsibility-part-2/>Part 2: Monitoring</a> | <a href=/posts/ai-systems-responsibility-part-3/>Part 3: Incident Response</a> | <a href=/posts/ai-systems-responsibility-part-4/>Part 4: Testing</a></em></p></div></div><div class=related-posts style="margin-top:3rem;padding-top:2rem;border-top:1px solid #333"><h3>Related Posts</h3><ul style=list-style:none;padding:0><li style=margin-bottom:1rem><a href=https://gazsecops.github.io/posts/ai-systems-responsibility-part-7/>AI Systems Responsibility: Part 7 - Why Smart People Keep Making Dumb Decisions</a>
<span style=color:#999;font-size:.9rem>- 23 Jan 2026</span><div style=font-size:.85rem;color:#666;margin-top:.25rem><span style=margin-right:.5rem>#ai</span>
<span style=margin-right:.5rem>#management</span>
<span style=margin-right:.5rem>#culture</span>
<span style=margin-right:.5rem>#operations</span>
<span style=margin-right:.5rem>#series</span></div></li><li style=margin-bottom:1rem><a href=https://gazsecops.github.io/posts/ai-systems-responsibility-part-8/>AI Systems Responsibility: Part 8 - Practical Tools That Actually Help (Bonus Episode)</a>
<span style=color:#999;font-size:.9rem>- 30 Jan 2026</span><div style=font-size:.85rem;color:#666;margin-top:.25rem><span style=margin-right:.5rem>#ai</span>
<span style=margin-right:.5rem>#tools</span>
<span style=margin-right:.5rem>#operations</span>
<span style=margin-right:.5rem>#series</span></div></li><li style=margin-bottom:1rem><a href=https://gazsecops.github.io/posts/ai-systems-responsibility-part-6/>AI Systems Responsibility: Part 6 - Case Studies (What Actually Goes Wrong)</a>
<span style=color:#999;font-size:.9rem>- 16 Jan 2026</span><div style=font-size:.85rem;color:#666;margin-top:.25rem><span style=margin-right:.5rem>#ai</span>
<span style=margin-right:.5rem>#case-studies</span>
<span style=margin-right:.5rem>#operations</span>
<span style=margin-right:.5rem>#series</span></div></li><li style=margin-bottom:1rem><a href=https://gazsecops.github.io/posts/ai-systems-responsibility-part-4/>AI Systems Responsibility: Part 4 - Testing Before You Ship (Or: Stop Discovering Bugs in Production)</a>
<span style=color:#999;font-size:.9rem>- 2 Jan 2026</span><div style=font-size:.85rem;color:#666;margin-top:.25rem><span style=margin-right:.5rem>#ai</span>
<span style=margin-right:.5rem>#testing</span>
<span style=margin-right:.5rem>#operations</span>
<span style=margin-right:.5rem>#series</span></div></li><li style=margin-bottom:1rem><a href=https://gazsecops.github.io/posts/ai-systems-responsibility-part-3/>AI Systems Responsibility: Part 3 - Incident Response When You Have No Idea Why</a>
<span style=color:#999;font-size:.9rem>- 19 Dec 2025</span><div style=font-size:.85rem;color:#666;margin-top:.25rem><span style=margin-right:.5rem>#ai</span>
<span style=margin-right:.5rem>#incident-response</span>
<span style=margin-right:.5rem>#operations</span>
<span style=margin-right:.5rem>#series</span></div></li></ul></div><div class=pagination><div class=pagination__title><span class=pagination__title-h></span><hr></div><div class=pagination__buttons><a href=https://gazsecops.github.io/posts/ai-systems-responsibility-part-6/ class="button inline prev">&lt; [<span class=button__text>AI Systems Responsibility: Part 6 - Case Studies (What Actually Goes Wrong)</span>]
</a>::
<a href=https://gazsecops.github.io/posts/ai-systems-responsibility-part-4/ class="button inline next">[<span class=button__text>AI Systems Responsibility: Part 4 - Testing Before You Ship (Or: Stop Discovering Bugs in Production)</span>] ></a></div></div></article></div><footer class=footer><div class=footer__inner><div class=copyright><span>© 2026</span></div><div class=build-info><span class=build-commit>e733073</span><span class=build-date>2026-02-12 12:33 UTC</span></div></div></footer></div></body></html>